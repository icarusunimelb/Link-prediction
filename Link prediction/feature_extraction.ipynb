{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np # linear algebra\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from networkx import NetworkXNoPath, NetworkXError, NodeNotFound\n",
    "from networkx.algorithms import community\n",
    "import os\n",
    "from scipy.sparse import csr_matrix\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# directed\n",
    "def predecessor_size(u, dig):\n",
    "    return len(set(dig.predecessors(u)))\n",
    "\n",
    "def successor_size(u, dig):\n",
    "    return len(set(dig.successors(u)))\n",
    "\n",
    "# distance 1\n",
    "# u:source is follower, v:sink is following\n",
    "def common_follower(u, v, dig):\n",
    "    return len(set(dig.predecessors(u)).intersection(set(dig.predecessors(v))))\n",
    "def common_following(u, v, dig):\n",
    "    return len(set(dig.successors(u)).intersection(set(dig.successors(v))))\n",
    "\n",
    "# distance 2\n",
    "def common_following_with_sink_followers(u, v, dig):\n",
    "    followers = list(dig.predecessors(v))\n",
    "    total_score = 0\n",
    "    for follower in followers:\n",
    "        total_score += common_following(u, follower, dig)\n",
    "    return total_score/(len(followers)+1)\n",
    "\n",
    "def common_follower_with_source_followings(u, v, dig):\n",
    "    followings = list(dig.successors(u))\n",
    "    total_score = 0\n",
    "    for following in followings:\n",
    "        total_score += common_follower(following, v, dig)\n",
    "    return total_score/(len(followings)+1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# undirected\n",
    "# following feature extraction methods comes from networkx library with slightly adaption\n",
    "# to make it work for single item\n",
    "def my_resource_allocation_index(g, u, v):\n",
    "    return sum(1 / g.degree(w) for w in nx.common_neighbors(g, u, v))\n",
    "\n",
    "def my_jaccard_coefficient(g, u, v):\n",
    "    union_size = len(set(g[u]) | set(g[v]))\n",
    "    if union_size == 0:\n",
    "        return 0\n",
    "    return len(list(nx.common_neighbors(g, u, v))) / union_size\n",
    "\n",
    "def my_adamic_adar_index(g, u, v):\n",
    "    return sum(1 / log(g.degree(w)) for w in nx.common_neighbors(g, u, v))\n",
    "\n",
    "def my_common_neighbor_centrality(g, u, v, alpha=0.8):\n",
    "    shortest_path = nx.shortest_path(g)\n",
    "    return alpha * len(list(nx.common_neighbors(g, u, v))) + (1 - alpha) * (\n",
    "            g.number_of_nodes() / (len(shortest_path[u][v]) - 1)\n",
    "        )\n",
    "\n",
    "def my_preferential_attachment(g, u, v):\n",
    "    return g.degree(u) * g.degree(v)\n",
    "\n",
    "def _community(g, u, community):\n",
    "    \"\"\"Get the community of the given node.\"\"\"\n",
    "    node_u = g.nodes[u]\n",
    "    try:\n",
    "        return node_u[community]\n",
    "    except KeyError as e:\n",
    "        raise nx.NetworkXAlgorithmError(\"No community information\") from e\n",
    "\n",
    "def my_cn_soundarajan_hopcroft(g, u, v, community=\"community\"):\n",
    "    Cu = _community(g, u, community)\n",
    "    Cv = _community(g, v, community)\n",
    "    cnbors = list(nx.common_neighbors(g, u, v))\n",
    "    neighbors = (\n",
    "        sum(_community(g, w, community) == Cu for w in cnbors) if Cu == Cv else 0\n",
    "    )\n",
    "    return len(cnbors) + neighbors\n",
    "\n",
    "def my_ra_index_soundarajan_hopcroft(g, u, v, community=\"community\"):\n",
    "    Cu = _community(g, u, community)\n",
    "    Cv = _community(g, v, community)\n",
    "    if Cu != Cv:\n",
    "        return 0\n",
    "    cnbors = nx.common_neighbors(g, u, v)\n",
    "    return sum(1 / g.degree(w) for w in cnbors if _community(g, w, community) == Cu)\n",
    "\n",
    "def my_within_inter_cluster(g, u, v, delta=0.001, community=\"community\"):\n",
    "    if delta <= 0:\n",
    "        raise nx.NetworkXAlgorithmError(\"Delta must be greater than zero\")\n",
    "    Cu = _community(g, u, community)\n",
    "    Cv = _community(g, v, community)\n",
    "    if Cu != Cv:\n",
    "        return 0\n",
    "    cnbors = set(nx.common_neighbors(g, u, v))\n",
    "    within = {w for w in cnbors if _community(g, w, community) == Cu}\n",
    "    inter = cnbors - within\n",
    "    return len(within) / (len(inter) + delta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data_processing/test_df.csv')\n",
    "\n",
    "edge_df = pd.read_csv('./data_processing/edge_df.csv')\n",
    "\n",
    "positive_data = pd.read_csv('./data_processing/positive_data.csv')\n",
    "\n",
    "negative_data = pd.read_csv('./data_processing/negative_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(edge_df, \"Source\", \"Sink\", create_using=nx.Graph())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DiG = nx.from_pandas_edgelist(edge_df, \"Source\", \"Sink\", create_using=nx.DiGraph())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NODE_NUM = 4867136\n",
    "data = np.ones(len(edge_df.index))\n",
    "source_sink_matrix=csr_matrix((data,(edge_df.Source,edge_df.Sink)),shape=(NODE_NUM,NODE_NUM))\n",
    "sink_source_matrix=csr_matrix((data,(edge_df.Sink,edge_df.Source)),shape=(NODE_NUM,NODE_NUM))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cosine_similarity(u,v):\n",
    "    try:\n",
    "        return (np.dot(u,v.T)/(sqrt(u.nnz)*sqrt(v.nnz))).toarray()[0][0]\n",
    "    except:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cosine_similarity_among_source_followers_and_sink_followers(u, v):\n",
    "    return cosine_similarity(sink_source_matrix[u],sink_source_matrix[v])\n",
    "def cosine_similarity_among_source_followings_and_sink_followers(u,v):\n",
    "    return cosine_similarity(source_sink_matrix[u],sink_source_matrix[v])\n",
    "def average_cosine_similarity_among_source_followings_followers_and_sink_followers(u,v):\n",
    "    feature=[0]*100\n",
    "    i = 0\n",
    "    for key in source_sink_matrix[u].nonzero()[1]:\n",
    "        feature[i]=(cosine_similarity(sink_source_matrix[key],sink_source_matrix[v]))\n",
    "        i+=1\n",
    "        if i >= 100:\n",
    "            break\n",
    "    feature = [value for value in feature if value != 0]\n",
    "    feature = sum(feature)/(len(feature)+1)\n",
    "    return feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate community\n",
    "communities = np.load('./data_processing/communities.npy', allow_pickle=True)\n",
    "for node in tqdm(G.nodes()):\n",
    "    for i in range(len(communities)):\n",
    "        if node in communities[i]:\n",
    "            G.nodes[node]['community'] = i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# The feature name here is different with the name in the report.\n",
    "# The reason is the report requires shorter name to satisfy the page limitation.\n",
    "training_data_frame = pd.DataFrame(columns=['sink_pre_siz',\n",
    "                                            'source_suc_siz',\n",
    "                                            'cosine_similarity_among_source_followers_and_sink_followers',\n",
    "                                            'cosine_similarity_among_source_followings_and_sink_followers',\n",
    "                                            'average_cosine_similarity_among_source_followings_and_sink',\n",
    "                                            'Common_Following', 'Common_Follower',\n",
    "                                            'Common_Following_With_Sink_Followers',\n",
    "                                            'Common_follower_with_source_followings',\n",
    "                                            'Resource_allocation_index',\n",
    "                                            'Jaccard_coefficient',\n",
    "                                            'Adamic_adar_index',\n",
    "                                            'Cn_soundarajan_hopcroft',\n",
    "                                            'Ra_index_soundarajan_hopcroft',\n",
    "                                            'Within_inter_cluster',\n",
    "                                            'Preferential_attachment',\n",
    "                                            'Label'])\n",
    "for index, row in tqdm(positive_data.iterrows()):\n",
    "    source = row['Source']\n",
    "    sink = row['Sink']\n",
    "    DiG.remove_edge(source, sink)\n",
    "    G.remove_edge(source, sink)\n",
    "    sample_sink_pre_siz = predecessor_size(sink, DiG)\n",
    "    sample_source_suc_siz = successor_size(source, DiG)\n",
    "    sample_pre_pre_cos = cosine_similarity_among_source_followers_and_sink_followers(source, sink)\n",
    "    sample_suc_pre_cos = cosine_similarity_among_source_followings_and_sink_followers(source, sink)\n",
    "    sample_uhi = average_cosine_similarity_among_source_followings_followers_and_sink_followers(source, sink)\n",
    "    sample_common_following = common_following(source, sink, DiG)\n",
    "    sample_common_follower = common_follower(source, sink, DiG)\n",
    "    sample_common_following_with_sink_followers = \\\n",
    "        common_following_with_sink_followers(source, sink, DiG)\n",
    "    sample_common_follower_with_source_followings = \\\n",
    "        common_follower_with_source_followings(source, sink, DiG)\n",
    "    sample_resource_allocation_index = my_resource_allocation_index(G, source, sink)\n",
    "    sample_jaccard_coefficient = my_jaccard_coefficient(G, source, sink)\n",
    "    sample_adamic_adar_index = my_adamic_adar_index(G, source, sink)\n",
    "    sample_preferential_attachment = my_preferential_attachment(G, source, sink)\n",
    "    sample_cn_soundarajan_hopcroft = my_cn_soundarajan_hopcroft(G, source, sink)\n",
    "    sample_ra_index_soundarajan_hopcroft = my_ra_index_soundarajan_hopcroft(G, source, sink)\n",
    "    sample_within_inter_cluster = my_within_inter_cluster(G, source, sink)\n",
    "    # common_neighbor_centrality: cost too much time\n",
    "    # positive_common_neighbor_centrality = my_common_neighbor_centrality(G, source, sink)\n",
    "    training_data_frame = training_data_frame.append(\n",
    "        {\n",
    "            'sink_pre_siz': sample_sink_pre_siz,\n",
    "            'source_suc_siz': sample_source_suc_siz,\n",
    "            'cosine_similarity_among_source_followers_and_sink_followers': sample_pre_pre_cos,\n",
    "            'cosine_similarity_among_source_followings_and_sink_followers': sample_suc_pre_cos,\n",
    "            'average_cosine_similarity_among_source_followings_and_sink': sample_uhi,\n",
    "            'Common_Following': sample_common_following,\n",
    "            'Common_Follower': sample_common_follower,\n",
    "            'Common_Following_With_Sink_Followers': sample_common_following_with_sink_followers,\n",
    "            'Common_follower_with_source_followings': sample_common_follower_with_source_followings,\n",
    "            'Resource_allocation_index': sample_resource_allocation_index,\n",
    "            'Jaccard_coefficient': sample_jaccard_coefficient,\n",
    "            'Adamic_adar_index': sample_adamic_adar_index,\n",
    "            'Cn_soundarajan_hopcroft': sample_cn_soundarajan_hopcroft,\n",
    "            'Ra_index_soundarajan_hopcroft': sample_ra_index_soundarajan_hopcroft,\n",
    "            'Within_inter_cluster': sample_within_inter_cluster,\n",
    "            'Preferential_attachment': sample_preferential_attachment,\n",
    "            'Label': row['Label']\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    DiG.add_edge(source, sink)\n",
    "    G.add_edge(source, sink)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in tqdm(negative_data.iterrows()):\n",
    "    source = row['Source']\n",
    "    sink = row['Sink']\n",
    "    sample_sink_pre_siz = predecessor_size(sink, DiG)\n",
    "    sample_source_suc_siz = successor_size(source, DiG)\n",
    "    sample_pre_pre_cos = cosine_similarity_among_source_followers_and_sink_followers(source, sink)\n",
    "    sample_suc_pre_cos = cosine_similarity_among_source_followings_and_sink_followers(source, sink)\n",
    "    sample_uhi = average_cosine_similarity_among_source_followings_followers_and_sink_followers(source, sink)\n",
    "    sample_common_following = common_following(source, sink, DiG)\n",
    "    sample_common_follower = common_follower(source, sink, DiG)\n",
    "    sample_common_following_with_sink_followers = \\\n",
    "        common_following_with_sink_followers(source, sink, DiG)\n",
    "    sample_common_follower_with_source_followings = \\\n",
    "        common_follower_with_source_followings(source, sink, DiG)\n",
    "    sample_resource_allocation_index = my_resource_allocation_index(G, source, sink)\n",
    "    sample_jaccard_coefficient = my_jaccard_coefficient(G, source, sink)\n",
    "    sample_adamic_adar_index = my_adamic_adar_index(G, source, sink)\n",
    "    sample_preferential_attachment = my_preferential_attachment(G, source, sink)\n",
    "    sample_cn_soundarajan_hopcroft = my_cn_soundarajan_hopcroft(G, source, sink)\n",
    "    sample_ra_index_soundarajan_hopcroft = my_ra_index_soundarajan_hopcroft(G, source, sink)\n",
    "    sample_within_inter_cluster = my_within_inter_cluster(G, source, sink)\n",
    "    # common_neighbor_centrality: cost too much time\n",
    "    # positive_common_neighbor_centrality = my_common_neighbor_centrality(G, source, sink)\n",
    "    training_data_frame = training_data_frame.append(\n",
    "        {\n",
    "            'sink_pre_siz': sample_sink_pre_siz,\n",
    "            'source_suc_siz': sample_source_suc_siz,\n",
    "            'cosine_similarity_among_source_followers_and_sink_followers': sample_pre_pre_cos,\n",
    "            'cosine_similarity_among_source_followings_and_sink_followers': sample_suc_pre_cos,\n",
    "            'average_cosine_similarity_among_source_followings_and_sink': sample_uhi,\n",
    "            'Common_Following': sample_common_following,\n",
    "            'Common_Follower': sample_common_follower,\n",
    "            'Common_Following_With_Sink_Followers': sample_common_following_with_sink_followers,\n",
    "            'Common_follower_with_source_followings': sample_common_follower_with_source_followings,\n",
    "            'Resource_allocation_index': sample_resource_allocation_index,\n",
    "            'Jaccard_coefficient': sample_jaccard_coefficient,\n",
    "            'Adamic_adar_index': sample_adamic_adar_index,\n",
    "            'Cn_soundarajan_hopcroft': sample_cn_soundarajan_hopcroft,\n",
    "            'Ra_index_soundarajan_hopcroft': sample_ra_index_soundarajan_hopcroft,\n",
    "            'Within_inter_cluster': sample_within_inter_cluster,\n",
    "            'Preferential_attachment': sample_preferential_attachment,\n",
    "            'Label': row['Label']\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_data_frame.to_csv('./data_processing/training_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "testing_data_frame = pd.DataFrame(columns=[ 'sink_pre_siz',\n",
    "                                            'source_suc_siz',\n",
    "                                            'cosine_similarity_among_source_followers_and_sink_followers',\n",
    "                                            'cosine_similarity_among_source_followings_and_sink_followers',\n",
    "                                            'average_cosine_similarity_among_source_followings_and_sink',\n",
    "                                            'Common_Following', 'Common_Follower',\n",
    "                                            'Common_Following_With_Sink_Followers',\n",
    "                                            'Common_follower_with_source_followings',\n",
    "                                            'Resource_allocation_index',\n",
    "                                            'Jaccard_coefficient',\n",
    "                                            'Adamic_adar_index',\n",
    "                                            'Cn_soundarajan_hopcroft',\n",
    "                                            'Ra_index_soundarajan_hopcroft',\n",
    "                                            'Within_inter_cluster',\n",
    "                                            'Preferential_attachment'])\n",
    "for index, row in tqdm(test_df.iterrows()):\n",
    "    source = row['Source']\n",
    "    sink = row['Sink']\n",
    "    testing_sink_pre_siz = predecessor_size(sink, DiG)\n",
    "    testing_source_suc_siz = successor_size(source, DiG)\n",
    "    testing_pre_pre_cos = cosine_similarity_among_source_followers_and_sink_followers(source, sink)\n",
    "    testing_suc_pre_cos = cosine_similarity_among_source_followings_and_sink_followers(source, sink)\n",
    "    testing_uhi = average_cosine_similarity_among_source_followings_followers_and_sink_followers(source, sink)\n",
    "    testing_common_following = common_following(source, sink, DiG)\n",
    "    testing_common_follower = common_follower(source, sink, DiG)\n",
    "    testing_common_following_with_sink_followers = \\\n",
    "        common_following_with_sink_followers(source, sink, DiG)\n",
    "    testing_common_follower_with_source_followings = \\\n",
    "        common_follower_with_source_followings(source, sink, DiG)\n",
    "    testing_resource_allocation_index = my_resource_allocation_index(G, source, sink)\n",
    "    testing_jaccard_coefficient = my_jaccard_coefficient(G, source, sink)\n",
    "    testing_adamic_adar_index = my_adamic_adar_index(G, source, sink)\n",
    "    testing_preferential_attachment = my_preferential_attachment(G, source, sink)\n",
    "    testing_cn_soundarajan_hopcroft = my_cn_soundarajan_hopcroft(G, source, sink)\n",
    "    testing_ra_index_soundarajan_hopcroft = my_ra_index_soundarajan_hopcroft(G, source, sink)\n",
    "    testing_within_inter_cluster = my_within_inter_cluster(G, source, sink)\n",
    "    #testing_common_neighbor_centrality = my_common_neighbor_centrality(G, source, sink)\n",
    "    testing_data_frame = testing_data_frame.append(\n",
    "        {\n",
    "            'sink_pre_siz': testing_sink_pre_siz,\n",
    "            'source_suc_siz': testing_source_suc_siz,\n",
    "            'cosine_similarity_among_source_followers_and_sink_followers': testing_pre_pre_cos,\n",
    "            'cosine_similarity_among_source_followings_and_sink_followers': testing_suc_pre_cos,\n",
    "            'average_cosine_similarity_among_source_followings_and_sink': testing_uhi,\n",
    "            'Common_Following': testing_common_following,\n",
    "            'Common_Follower': testing_common_follower,\n",
    "            'Common_Following_With_Sink_Followers': testing_common_following_with_sink_followers,\n",
    "            'Common_follower_with_source_followings': testing_common_follower_with_source_followings,\n",
    "            'Resource_allocation_index': testing_resource_allocation_index,\n",
    "            'Jaccard_coefficient': testing_jaccard_coefficient,\n",
    "            'Adamic_adar_index': testing_adamic_adar_index,\n",
    "            'Cn_soundarajan_hopcroft': testing_cn_soundarajan_hopcroft,\n",
    "            'Ra_index_soundarajan_hopcroft': testing_ra_index_soundarajan_hopcroft,\n",
    "            'Within_inter_cluster': testing_within_inter_cluster,\n",
    "            'Preferential_attachment': testing_preferential_attachment\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "testing_data_frame.to_csv('./data_processing/testing_data.csv')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}